const template =
`# <%= model %>を使った<%= target %>と選択された予測変数の関係の分析

目的変数である<%= target %>と選択された予測変数との関係を調べるためにXGBoostを使った予測モデルが作られました。

# サマリ

## 予測精度

{{summary}}

**<%= target %>の予測精度**

<% if (auc > 0.9) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と非常に高く、このモデルは<%= target %>のTRUEとFALSEをうまく切り分けられていることを示しています。
<% } else if (auc > 0.8) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と高く、このモデルは<%= target %>のTRUEとFALSEを切り分けられていることを示しています。
<% } else if (auc > 0.7) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と中程度で、このモデルは<%= target %>のTRUEとFALSEをある程度切り分けられていることを示しています。
<% } else { %>
AUCは<%= auc_pct %>% (<%= auc %>)と低く、このモデルは<%= target %>のTRUEとFALSEをあまり切り分けられていないことを示しています。
<% } %>

**モデルの性能指標**

* 正解率: 全体の約<%= accuracy_pct %>%のケースで<%= target %>を正しく予測できています。
* 適合率: モデルが「<%= target %>がTRUE」と予測したケースのうち、実際にTRUEだったのは約<%= precision_pct %>%です。
* 再現率: 実際に「<%= target %>がTRUE」だったケースのうち、モデルが正しくTRUEと予測できたのは約<%= recall_pct %>%です。
* F1スコア: 適合率と再現率のバランスを示すF1スコアは<%= f1_score %>となっています。

## 選択された予測変数と<%= target %>の関係の強さ

選択された予測変数と<%= target %>の関係の強さを相対的に表したのが以下のチャートです。

{{variable_importance}}

## それぞれの予測変数と<%= target %>の関係

それぞれの予測変数の値が変わると、<%= target %>の確率がどのように変わるかを表したのが以下のチャートです。変数は<%= target %>との関係が最も強いものから弱い方への順番で並んでいます。

{{variable_effect_logical}}

# 次のステップ

* 変数選択の最適化：変数重要度が低い予測変数を除外して、モデルをシンプルにすることを検討してください。これにより、モデルの解釈がしやすくなり、過剰適合のリスクも減少します。
* グループ別分析：グループごとに別々のモデルを作成することで、それぞれのグループ内での<%= target %>の決定要因をより詳細に理解できるかもしれません。その場合は、「繰り返し」にグループとなる変数を選択し、実行し直すことができます。
* 外れ値の確認：予測精度に影響を与える可能性のある外れ値がないか確認し、必要に応じて対処することで、モデルの信頼性が向上する可能性があります。
* モデルの評価：このモデルの予測性能をより厳密に評価するために、トレーニングデータとテストデータに分けて検証することを検討してください。
* TRUE/FALSEの境界値の調整：予測のTRUE/FALSEの境界値を調整することで、適合率と再現率のバランスを変えることができます。TRUE/FALSEの境界値を変更したい場合は、設定から変更が可能です。
* パラメータの調整：XGBoostのパラメータ（木の深さ、学習率、学習回数など）を調整することで、モデルの性能をさらに向上させることができるかもしれません。

# 補足情報

## トレーニングデータに対する予測

元のデータに対して、作成された予測モデルを使って予測した結果が以下の表となります。

{start_lazy_show_hide}
### チャート
{{data}}
{end_lazy_show_hide}

## 予測マトリックス

この表は、モデルの予測結果と実際の結果の対応関係を示す予測マトリックスです。各セルの値は全体に対する割合（%）を表しています。

{start_lazy_show_hide}
### チャート
{{confusion_matrix}}
{end_lazy_show_hide}

## 予測確率分布

このチャートは、モデルが予測した<%= target %>の確率（0～1の間の値）を実際にTRUEのケース（青線）、実際にFALSEのケース（オレンジの線）に分けて密度曲線として可視化しています。
理想的には、実際にTRUEのケース（青線）は右側（1に近い確率）に、実際にFALSEのケース（オレンジ線）は左側（0に近い確率）に集中しているほど、モデルの予測精度が高いと言えます。縦の点線は、TRUEとFALSEを分類するために使用されているTRUE/FALSEの境界値を示しています。この分布からモデルの分類性能や、最適なTRUE/FALSEの境界値の調整を視覚的に確認できます。

{start_lazy_show_hide}
### チャート
{{probability_distribution}}
{end_lazy_show_hide}

## ROC曲線

この曲線は、モデルの分類性能を様々な閾値で評価するROC曲線です。Y軸は真陽性率（感度）、X軸は偽陽性率（1-特異度）を表しています。青い線は今回のモデルのROC曲線で、対角線の灰色の点線はランダムな予測（AUC: 0.5）を意味します。

{start_lazy_show_hide}
### チャート
{{roc_curve}}
{end_lazy_show_hide}

## 学習回数と精度の向上

モデルの学習過程を表したのが以下のチャートです。横軸は学習回数、縦軸はRMSE（予測誤差）を表しています。
XGBoostは学習回数が増えるごとにRMSEが減少していき初期の学習ではRMSEが急速に減少し、その後は緩やかになっていく傾向があります。
学習曲線が平坦化してきた場合は、最適な学習回数に近づいている可能性があります。逆に、まだ誤差が減少し続けている場合は、さらに学習回数を増やすことで性能向上が見込める可能性があります。

{start_lazy_show_hide}
### チャート
{{learning_curve_logical}}
{end_lazy_show_hide}
`;

module.exports = template;
