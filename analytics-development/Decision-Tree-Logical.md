const template = `
# <%= model %>を使った<%= target %>と選択された予測変数の関係の分析

目的変数である<%= target %>と選択された予測変数との関係を調べるために決定木を使った予測モデルが作られました。

# サマリ

## 予測精度

{{summary}}
{start_show_hide}
## 主要な統計指標

* AUC
  * AUC（Area Under the Curve）はROC曲線の下の面積で、モデルの分類性能を総合的に評価する指標です。
  * 値は0.5から1の間で、0.5はランダムな予測（コイン投げと同等）、1はTRUEとFALSEをうまく切り分けられている完璧な分類を意味します。
  * 一般的に0.7以上で許容可能、0.8以上で良好、0.9以上で非常に優れた分類性能と解釈されます。

* F1スコア
  * F1スコアは適合率と再現率の調和平均で、両方のバランスを考慮した分類性能の指標です。
  * 値は0から1の間で、1に近いほど精度と網羅性のバランスが取れた優れた分類器を意味します。
  * 元データのTRUEとFALSEの割合に大きな差がある場合に特に有用です。

* 正解率
  * 正解率（Accuracy）は全予測中の正しい予測の割合を示します。
  * 値は0から1の間で、1に近いほど多くの事例を正しく分類できることを意味します。
  * 元データのTRUEとFALSEの割合に大きな差がある場合、不均衡がある場合は誤解を招く可能性があります。

* 誤分類率
  * 誤分類率（Error Rate）は全予測中の誤った予測の割合で、1-正解率で計算されます。
  * 値は0から1の間で、0に近いほど誤分類が少ないことを意味します。
  * 正解率と同様に、元データのTRUEとFALSEの割合に大きな差がある場合は解釈に注意が必要です。

* 適合率 (Precision)
  * 適合率は「TRUEと予測したもののうち、実際にTRUEだった割合」を示します。
  * 値は0から1の間で、1に近いほど「TRUEと予測したものが実際にTRUEである精度」が高いことを意味します。
  * 偽陽性（実際はFALSEなのにTRUEと予測）を最小化したい場合に重視される指標です。

* 再現率 (Recall)
  * 再現率は「実際にTRUEであるもののうち、TRUEと正しく予測できた割合」を示します。
  * 値は0から1の間で、1に近いほど「実際のTRUEのケースを見逃さない能力」が高いことを意味します。
  * 偽陰性（実際はTRUEなのにFALSEと予測）を最小化したい場合に重視される指標です。

* 行数 (TRUE)
  * 目的変数がTRUEのデータの行数を示します。
  * 極端にTRUEが少ない場合、モデルの学習や評価に偏りが生じる可能性があります。

* 行数 (FALSE)
  * 目的変数がFALSEのデータの行数を示します。
  * 極端にFALSEが少ない場合、モデルの学習や評価に偏りが生じる可能性があります。

* 行数
  * 行数は分析に使用したデータの総数（サンプルサイズ）です。
  * データ数が多いほど、モデルの信頼性が高まります。

* 対数尤度
  * 対数尤度はモデルがデータにどれだけ適合しているかを数値化したものです。
  * 通常は負の値を取り、0に近いほどモデルの適合度が高いことを示します。
  * 単独では解釈が難しく、モデル比較のためのAICやBICの計算に使用されます。
{end_show_hide}

**<%= target %>の予測精度**

<% if (auc > 0.9) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と非常に高く、このモデルは<%= target %>のTRUEとFALSEをうまく切り分けられていることを示しています。
<% } else if (auc > 0.8) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と高く、このモデルは<%= target %>のTRUEとFALSEを切り分けられていることを示しています。
<% } else if (auc > 0.7) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と中程度で、このモデルは<%= target %>のTRUEとFALSEをある程度切り分けられていることを示しています。
<% } else { %>
AUCは<%= auc_pct %>% (<%= auc %>)と低く、このモデルは<%= target %>のTRUEとFALSEをあまり切り分けられていないことを示しています。
<% } %>

**モデルの性能指標**

* 正解率: 全体の約<%= accuracy_pct %>%のケースで<%= target %>を正しく予測できています。
* 適合率: モデルが「<%= target %>がTRUE」と予測したケースのうち、実際にTRUEだったのは約<%= precision_pct %>%です。
* 再現率: 実際に「<%= target %>がTRUE」だったケースのうち、モデルが正しくTRUEと予測できたのは約<%= recall_pct %>%です。
* F1スコア: 適合率と再現率のバランスを示すF1スコアは<%= f1_score %>となっています。

## 選択された予測変数と<%= target %>の関係の強さ

選択された予測変数と<%= target %>の関係の強さを相対的に表したのが以下のチャートです。

{{variable_importance}}

## それぞれの予測変数と<%= target %>の関係

それぞれの予測変数の値が変わると、<%= target %>の確率がどのように変わるかを表したのが以下のチャートです。変数は<%= target %>との関係が最も強いものから弱い方への順番で並んでいます。

{{variable_effect_logical}}

## 決定木の構造

以下のチャートは、作成された決定木の構造を可視化したもので、<%= target %>を予測する際に作られた条件分岐を確認することができます。

{{tree_structure}}

**決定木の読み方**

- **ノードとブランチ**: 各ボックスはノード（決定点または葉）を表し、そこから伸びる線はブランチ（枝）と呼ばれる分岐を示しています。
- **条件分岐**: 各内部ノードには分割する際の条件（例：「変数A < 値X」）が表示されており、この条件に基づいて左右に分岐します。
 - 左側のブランチは条件が「yes（真）」の場合
 - 右側のブランチは条件が「no（偽）」の場合

**ノード内の情報**

各ノードには以下の情報が含まれています。

- **上段**: そのノードにおけるTRUEまたはFALSEの多数派
- **中段のパーセンテージ**: そのノードに含まれるサンプルの中でのTRUEの割合（%）
- **下段のパーセンテージ**: 全体に対するそのノードに含まれるサンプルの割合（%）

# 次のステップ

* 変数選択の最適化：変数重要度が低い予測変数を除外して、モデルをシンプルにすることを検討してください。これにより、モデルの解釈がしやすくなり、過剰適合のリスクも減少します。
* 外れ値の確認：予測精度に影響を与える可能性のある外れ値がないか確認し、必要に応じて対処することで、モデルの信頼性が向上する可能性があります。
* モデルの評価：このモデルの予測性能をより厳密に評価するために、訓練データとテストデータに分けて検証することを検討してください。
* TRUE/FALSEの境界値の調整：予測のTRUE/FALSEの境界値を調整することで、適合率と再現率のバランスを変えることができます。TRUE/FALSEの境界値を変更したい場合は、設定から変更が可能です。
* アンサンブル学習の手法の検討：単一の決定木では捉えられないパターンを捉えるために、ランダムフォレストやXGBoostといったアンサンブル学習の手法を検討することも有効かもしれません。

# 補足情報

## トレーニングデータに対する予測

元のデータに対して、作成された予測モデルを使って予測した結果が以下の表となります。

{start_lazy_show_hide}
### チャート
{{data}}
{end_lazy_show_hide}

## 予測マトリックス

この表は、モデルの予測結果と実際の結果の対応関係を示す予測マトリックスです。各セルの値は全体に対する割合（%）を表しています。

{start_lazy_show_hide}
### チャート
{{confusion_matrix}}
{end_lazy_show_hide}

## 予測確率分布

このチャートは、モデルが予測した<%= target %>の確率（0～1の間の値）を実際にTRUEのケース（青線）、実際にFALSEのケース（オレンジの線）に分けて密度曲線として可視化しています。
理想的には、実際にTRUEのケース（青線）は右側（1に近い確率）に、実際にFALSEのケース（オレンジ線）は左側（0に近い確率）に集中しているほど、モデルの予測精度が高いと言えます。縦の点線は、TRUEとFALSEを分類するために使用されているTRUE/FALSEの境界値を示しています。この分布からモデルの分類性能や、最適なTRUE/FALSEの境界値の調整を視覚的に確認できます。

{start_lazy_show_hide}
### チャート
{{probability_distribution}}
{end_lazy_show_hide}

## ROC曲線

この曲線は、モデルの分類性能を様々な閾値で評価するROC曲線です。Y軸は真陽性率（感度）、X軸は偽陽性率（1-特異度）を表しています。青い線は今回のモデルのROC曲線で、対角線の灰色の点線はランダムな予測（AUC: 0.5）を意味します。

{start_lazy_show_hide}
### チャート
{{roc_curve}}
{end_lazy_show_hide}
`;
module.exports = template;
