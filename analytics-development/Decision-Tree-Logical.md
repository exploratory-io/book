const template = `
<br/>
<!-- intentional new line feed above -->

選択された説明変数を元に、<%= target %>を予測する決定木のモデルを作成しました。

# 変数間の関係

<% if (predictorColumns.length > 1) { %>
## 変数の重要度

<%= target %>を予測するためにどの説明変数が相対的により重要なのかを表したのが以下のチャートです。

{{variable_importance}}

変数の重要度の仕組みについては、[こちら](https://exploratory.io/note/exploratory/dLm5rwn5)のノートをご覧ください。

<% } %>

## 変数の影響度

<% if (predictorColumns.length > 1) { %>
それぞれの説明変数の確率が変わると<%= target %>の値がどのように変わるかを表したのが以下のチャートです。
<% } else { %>
説明変数の値が変わると<%= target %>の確率がどのように変わるかを表したのが以下のチャートです。
<% } %>

{{variable_effect}}

* 青い線（または点）は説明変数の値に対する予測値を示します。
* グレーの線は実測値とその95%信頼区間を示します。
* 縦軸は<%= target %>の確率です。

注意点：

<% if (predictorColumns.length > 1) { %>

* 他の変数が一定だとした時に、その説明変数単体の効果を予測しているため、実測値の平均値と予測値にずれが生じます。
* 予測値の計算方法の詳細は、[こちらのノート](https://exploratory.io/note/exploratory/Sbd0LDU6)をご参照ください。
* 説明変数は上記の「説明変数の重要度」にある重要度の高い順番で並んでいます。

<% } %>
* カテゴリー型（Character型、Factor型）の説明変数において一意の値が12個より多い場合は、頻度の多いものから11個の値を残し、それ以外は「その他」としています。これは[「設定」](//analytics/settings)より変更可能です。

# 決定木

データを下に作成された決定木（一連の条件分岐）を可視化したものが以下です。<%= target %>を予測する際に作られた条件分岐を確認することができます。

{{tree_structure}}

**決定木の読み方**

それぞれの箱はノードと呼ばれ、そこから伸びる線はブランチ（枝）と呼ばれます。

- **条件分岐**: 各ノードの下には条件（例：「変数A < 値X」）が表示されており、この条件に基づいて左右に分岐します。
 - 左側のブランチは条件が「yes（真）」の場合
 - 右側のブランチは条件が「no（偽）」の場合
- **ノード内の情報**
 - **上段**: 各ノードに含まれるデータのTRUEまたはFALSEのうちの多数派
 - **中段**: 各ノードに含まれるデータのTRUEの割合
 - **下段**: 各ノードに含まれるデータの全体に対する割合（%）

 一番下のノードの上段の値とそれに対応する中断の割合が決定木のモデルを使った際の予測値となります。

# モデルの指標

<% if (!test_mode) { %>
モデルの予測精度や有意性に関する様々な指標を以下の表にまとめています。
<% } else { %>
モデルの予測精度や有意性に関する様々な指標を、以下の表にまとめています。現在テストモードであるため、予測精度に対してはトレーニングデータとテストデータ両方に対しての指標を表示しています。
<% } %>

{{summary}}

<% if (repeat_by) { %>

## 予測精度

<% if (groups.some(group => group.auc >= 0.8)) { %>
以下のグループにおいては、AUCが高いため（0.8以上）、選択された説明変数で<%= target %>のTRUEとFALSEのデータを非常にうまく分類できることを示しています。
 <% groups.forEach(group => { %>
   <% if (group.auc >= 0.8) { %>
* <%= group.name %>
   <% } %>
 <% }); %>
<% } else if (group => group.auc >= 0.6) { %>
以下のグループにおいては、AUCが中程度なため（0.6以上）、選択された説明変数で<%= target %>のTRUEとFALSEのデータをある程度うまく分類できることを示しています。
 <% groups.forEach(group => { %>
   <% if (group.auc >= 0.6) { %>
* <%= group.name %>
   <% } %>
 <% }); %>
<% } else { %>
<% } %>

### 予測精度の指標

* ロジカル型（TRUE/FALSE）を予測するモデルの予測精度の評価には一般的にAUCがよく使われます。値は0.5から1の間で、0.5はランダムな予測（コイン投げと同等）、1はTRUEとFALSEのデータを完全に分類できることを意味します。
* AUCの詳細な説明については、[こちら](https://exploratory.io/note/exploratory/AUC-RZG7gbI6)のノートをご覧ください。
* 正解率、誤分類率、F1スコア、適合率、再現率はTRUE/FALSEの境界値の設定により影響されます。現在の境界値は<%= true_false_criteria %>に設定されていますが、これは[「設定」](//analytics/settings)より変更可能です。


<% } else { %>
## 予測精度

<% if (auc > 0.9) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と非常に高く、このモデルは<%= target %>のTRUEとFALSEのデータを非常にうまく分類できることを示しています。
<% } else if (auc > 0.8) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と高く、このモデルは<%= target %>のTRUEとFALSEのデータをうまく分類できることを示しています。
<% } else if (auc > 0.6) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と中程度で、このモデルは<%= target %>のTRUEとFALSEのデータをある程度うまく分類できることを示しています。
<% } else { %>
AUCは<%= auc_pct %>% (<%= auc %>)と低く、このモデルは<%= target %>のTRUEとFALSEをあまりうまく分類できないことを示しています。
<% } %>

### 予測精度の指標

* ロジカル型（TRUE/FALSE）を予測するモデルの予測精度の評価には一般的にAUCがよく使われます。値は0.5から1の間で、0.5はランダムな予測（コイン投げと同等）、1はTRUEとFALSEのデータを完全に分類できることを意味します。
* 正解率、誤分類率、F1スコア、適合率、再現率はTRUE/FALSEの境界値の設定により影響されます。現在の境界値は<%= true_false_criteria %>に設定されていますが、これは[「設定」](//analytics/settings)より変更可能です。

<% } %>

{start_show_hide}
## モデルの指標の詳細

* AUC
 * ロジカル型の目的変数を予測するモデルの予測精度を評価するために、一般的によく使われる指標です。
 * このモデルがTRUEのデータとFALSEのデータをうまく分類することができるかを測ります。
 * 値は0.5から1の間で、0.5はランダムな予測（コイン投げと同等）、1はTRUEとFALSEのデータを完全に分類できることを意味します。
 * 一般的に0.6以上で許容可能、0.8以上で良好、0.9以上で非常に優れた分類性能と解釈されます。
 * Area Under the Curveの略で、ROC曲線（the Curve）の下の面積という意味です。

* F1スコア
 * F1スコアは適合率と再現率の調和平均で、両方のバランスを考慮したモデルの予測精度の指標です。
 * 値は0から1の間で、1に近いほど適当性と再現性のバランスが取れた優れたモデルであることを示します。
 * 元データのTRUEとFALSEの割合に大きな差がある場合に特に有用です。

* 正解率
 * 正解率（Accuracy）は全予測中の正しい予測の割合を示します。
 * 値は0から1の間で、1に近いほど多くの事例を正しく分類できることを意味します。
 * 元データのTRUEとFALSEの割合に大きな差がある場合、不均衡がある場合は誤解を招く可能性があります。

* 誤分類率
 * 誤分類率（Error Rate）は全予測中の誤った予測の割合で、1-正解率で計算されます。
 * 値は0から1の間で、0に近いほど誤分類が少ないことを意味します。
 * 正解率と同様に、元データのTRUEとFALSEの割合に大きな差がある場合は解釈に注意が必要です。

* 適合率 (Precision)
 * 適合率は「TRUEと予測したもののうち、実際にTRUEだった割合」を示します。
 * 値は0から1の間で、1に近いほど「TRUEと予測したものが実際にTRUEである精度」が高いことを意味します。
 * 偽陽性（実際はFALSEなのにTRUEと予測）を最小化したい場合に重視される指標です。

* 再現率 (Recall)
 * 再現率は「実際にTRUEであるもののうち、TRUEと正しく予測できた割合」を示します。
 * 値は0から1の間で、1に近いほど「実際のTRUEのケースを見逃さない能力」が高いことを意味します。
 * 偽陰性（実際はTRUEなのにFALSEと予測）を最小化したい場合に重視される指標です。

* 行数 (TRUE)
 * 目的変数がTRUEのデータの行数を示します。
 * 極端にTRUEが少ない場合、モデルの学習や評価に偏りが生じる可能性があります。

* 行数 (FALSE)
 * 目的変数がFALSEのデータの行数を示します。
 * 極端にFALSEが少ない場合、モデルの学習や評価に偏りが生じる可能性があります。

* 行数
 * 行数は分析に使用したデータの総数（サンプルサイズ）です。
 * データ数が多いほど、モデルの信頼性が高まります。
 * 一般的に説明変数の数の10倍以上のサンプルサイズが推奨されます。

 {end_show_hide}

## 予測マトリックス（混同行列）

<% if (!test_mode) { %>
モデルが<%= mode %>データの各行に対して予測したうち、どれだけが実測値と同じまたは違った値だったのかを対応表としてまとめたのが以下の表です。数値はそれぞれの組み合わせが全データに占める割合（％）です。

<% } else { %>
モデルが<%= mode %>データの各行に対して予測したうち、どれだけが実測値と同じまたは違った値だったのかを対応表としてまとめたのが以下の表です。数値はそれぞれの組み合わせが全データに占める割合（％）です。現在テストモードであるため、トレーニングデータ、テストデータそれぞれに対する結果を表示しています。

<% } %>

{{confusion_matrix}}

## 予測確率の分布

このモデルは<%= mode %>データのそれぞれの行に対して<%= target %>の確率（0～1の間の値）を予測したわけですが、この確率の値の分布を実測値がTRUE（青）、FALSE（オレンジ）のグループに分けて可視化したのが以下のチャートです。

{{probability_distribution}}

<% if (test_mode) { %>
* 現在テストモードであるため、テストデータに対して予測した確率の分布となります。
<% } %>
* 実測値がTRUEのグループ（青線）は右側（1に近い確率）に、実測値がFALSEのグループ（オレンジ線）は左側（0に近い確率）に偏っているほど、モデルの予測精度が高いと言えます。
* 縦の点線は、TRUEとFALSEを分類するために現在設定されている確率の境界値を示しています。デフォルトは50％（0.5）ですが、[「設定」](//analytics/settings)より変更可能です。
* この分布からモデルの分類性能や、最適なTRUE/FALSEの境界値の調整を視覚的に確認できます。

## ROC曲線

<% if (!test_mode) { %>
モデルの分類性能を様々なTRUE/FALSEの境界値で評価するROC曲線が以下のチャートです。Y軸は真陽性率（感度）、X軸は偽陽性率（1-特異度）を表しています。青い線は今回のモデルのROC曲線で、対角線の灰色の点線はランダムな予測（AUC: 0.5）を意味します。ROC曲線は左上に膨らむほど予測精度が高く、対角線に近いほど予測精度が低いことを示します。
<% } else { %>
モデルの分類性能を様々なTRUE/FALSEの境界値で評価するROC曲線が以下のチャートです。Y軸は真陽性率（感度）、X軸は偽陽性率（1-特異度）を表しています。青い線は今回のモデルのテストデータに対するROC曲線、オレンジの線はトレーニングデータに対するROC曲線です。対角線の灰色の点線はランダムな予測（AUC: 0.5）を意味します。ROC曲線は左上に膨らむほど予測精度が高く、対角線に近いほど予測精度が低いことを示します。
<% } %>

{{roc_curve}}

## 予測結果

全データに対して、作成された予測モデルを使って予測した結果が以下の表となります。

{start_lazy_show_hide}
### テーブル
{{data}}
{end_lazy_show_hide}

# 補足情報

## 次のステップ

* 変数選択の最適化：変数重要度が低い説明変数を除外して、モデルをシンプルにすることを検討してください。これにより、モデルの解釈がしやすくなり、過剰適合のリスクも減少します。変数選択のガイドラインは[こちら](https://exploratory.io/note/exploratory/SWF4cTx8)のノートをご覧ください。
* 外れ値の確認：予測精度に影響を与える可能性のある外れ値がないか確認し、必要に応じて対処することで、モデルの信頼性が向上する可能性があります。外れ値を除去する方法については、[こちら](https://exploratory.io/note/exploratory/Eep7kip3)のノートをご覧ください。
* TRUE/FALSEの境界値の調整：予測のTRUE/FALSEの境界値を調整することで、適合率と再現率のバランスを変えることができます。TRUE/FALSEの境界値を変更したい場合は、設定から変更が可能です。
* アンサンブル学習の手法の検討：単一の決定木では捉えられないパターンを捉えるために、ランダムフォレストやXGBoostといったアンサンブル学習の手法を検討することも有効かもしれません。
<% if (!test_mode) { %>
* モデルの評価：このモデルの予測性能をより厳密に評価するために、トレーニングデータとテストデータに分けて検証することができます。その場合は、[「設定」](//analytics/settings)より「検証」セクションの下の「テストモード」をTRUEに設定し、実行し直してください。
<% } %>
* 新しいデータに対する予測：作成したモデルを使って新しいデータに対して予測をしたいときには、予測をしたい対象のデータフレームに「モデルで予測（アナリティクス・ビュー）」のステップを追加します。詳細は、[こちらのノート](https://exploratory.io/note/exploratory/AAI3Mle3)をご参照ください。

`;
module.exports = template;
