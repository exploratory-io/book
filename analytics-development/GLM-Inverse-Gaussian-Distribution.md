const template = `

選択された説明変数を元に、<%= target %>を予測する一般化線形モデル（逆ガウス分布）を作成しました。

<% if (predictorColumns.length > 1) { %>
# 多重共線性

<% if (has_perfect_collinearity) { %>
{{multicollinearity:0.6}}

このモデルでは<%= perfect_collinearity_variables %>が完全な[多重共線性](https://exploratory.io/note/exploratory/Ysc3LNp0)（他の説明変数の値によって数式で完全に計算できる状態）の問題を作っているため、そのVIFスコアが無限大となり多重共線性をテストするためのチャートが生成できませんでした。多重共線性の問題を解決するために、<%= perfect_collinearity_variables %>を説明変数から除外し再実行してください。
<% } else if (max_vif > 10) { %>
{{multicollinearity}}

このモデルには[多重共線性](https://exploratory.io/note/exploratory/Ysc3LNp0)（複数の説明変数間に強い相関関係があること）の問題が見られます。VIFの値が10を超えている説明変数があると、個々の変数の効果を正確に評価することが難しくなります。
この問題を解決するためには、VIFの値が10を超えている説明変数の中から必要性が低いものを1つずつ除外し、再実行し、VIFの値が10を超える説明変数がなくなるまで繰り返してください。

<% } else { %>
{{multicollinearity}}

このモデルには[多重共線性](https://exploratory.io/note/exploratory/Ysc3LNp0)（複数の説明変数間に強い相関関係があること）の問題は見られません。（VIFの値が10を超えている説明変数があると、個々の変数の効果を正確に評価することが難しくなります。）
<% } %>
<% } %>

# 変数間の関係

<% if (predictorColumns.length > 1) { %>
## 説明変数の重要度

<%= target %>を予測するためにどの説明変数が相対的により重要なのかを表したのが以下のチャートです。

{{variable_importance}}

変数の重要度の仕組みについては、[こちら](https://exploratory.io/note/exploratory/dLm5rwn5)のノートをご覧ください。

<% } %>

## 説明変数の影響度

<% if (predictorColumns.length > 1) { %>
他の変数の値が一定であったとき、それぞれの説明変数の値が変わると<%= target %>の値がどのように変わるかを表したのが以下のチャートです。
<% } else { %>
説明変数の値が変わると<%= target %>の値がどのように変わるかを表したのが以下のチャートです。
<% } %>

{{variable_effect}}

* 青い線（または点）は説明変数の値に対する予測値を示します。
* グレーの線は実測値とその95%信頼区間を示します。
* 縦軸は<%= target %>の値です。

注意点：

<% if (predictorColumns.length > 1) { %>

* 他の変数が一定だとした時に、その説明変数単体の効果を予測しているため、実測値の平均値と予測値にずれが生じます。
* 予測値の計算方法の詳細は、[こちらのノート](https://exploratory.io/note/exploratory/Sbd0LDU6)をご覧ください。
* 単回帰分析と重回帰分析の解釈の違いについては、[こちらのノート](https://exploratory.io/note/exploratory/BDI7AeE5)をご覧ください。
* 説明変数は上記の「説明変数の重要度」にある重要度の高い順番で並んでいます。

<% } %>

<% if (has_category_columns) { %>
* カテゴリー型（Character型、Factor型）の説明変数において一意の値が12個より多い場合は、頻度の多いものから11個の値を残し、それ以外は「その他」としています。これは[「設定」](//analytics/settings)より変更可能です。
<% } %>

# 変数の係数と有意性

変数ごとに係数（傾き）とその有意性を判断するためのP値、および信頼区間がリストされています。

{{coefficient_table}}

## 係数の解釈

それぞれの変数の値が1単位変わると<%= target %>の値がどれほど変わるのかを示したのが係数です。


## P値を使った有意性の判断

有意水準が<%= baseline_p_pct %>% (<%= baseline_p %>)の元では、P値が<%= baseline_p_pct %>% (<%= baseline_p %>)よりも大きい説明変数は<%= target %>との関係が統計的に有意だとは言えません。逆に、P値が<%= baseline_p_pct %>% (<%= baseline_p %>)よりも小さい説明変数は<%= target %>との関係が統計的に有意だと言えます。

_現在の有意水準（P値）は<%= baseline_p_pct %>% (<%= baseline_p %>)に設定されていますが、これはアナリティクスの[「設定」](//analytics/settings)より変更可能です。_

## 係数と信頼区間の可視化

それぞれの変数の係数と信頼区間をエラーバーを使って可視化したのが以下です。

{{coefficient}}

* それぞれのエラーバーの真ん中の点は係数の値、上下の線はその95%信頼区間を表しています。<%= target %>との関係が有意で、かつその関係が正の説明変数は青、関係が負の説明変数は赤となっています。グレーで表されている説明変数は<%= target %>との関係が有意とは言えません。
* 係数の95%信頼区間は、「真の係数がこの範囲内にある可能性が高い（95%の信頼がある」ことを意味します。そのため、95%信頼区間が0を含んでいる説明変数は、<%= target %>との関係が全くない可能性があるため、統計的に有意だと言えません。逆に、95%信頼区間が0を含んでいない説明変数は、<%= target %>との関係が全くない可能性はほぼないため、統計的に有意だと言えます。
* 有意性の判断はP値または信頼区間によって行うことができ、どちらで判断しても同じ結果となります。

_上記の信頼区間の説明は直感的な説明であって、正確には「同じ母集団から繰り返しサンプルを取り、毎回95％信頼区間を計算した場合、そのうちの95％の区間は真の係数を含む」ということになります。_

### 注意点

これらの係数の値は、あくまでもそれぞれの説明変数の値が1ポイント変わった場合の変化量であり、説明変数同士で単位が異なる場合にはそれらの係数の値を使って<%= target %>との関係の強さを比べることはできません。説明変数間の関係の強さを比べたい場合は、上記の「説明変数の重要度」をご参照ください。

# モデルの指標

<% if (test_mode) { %>
モデルの予測精度や有意性に関する様々な指標を、以下の表にまとめています。現在テストモードであるため、予測精度に対してはトレーニングデータとテストデータ両方に対しての指標を表示しています。
<% } else { %>
モデルの予測精度や有意性に関する様々な指標を以下の表にまとめています。
<% } %>

{{summary}}

## 予測精度

ポアソン分布のGLMの予測モデルの予測精度を評価する指標として残差逸脱度がよく使われます。

* 残差逸脱度
  * 残差逸脱度は実測値とモデルによる予測値との差（残差）の二乗和を表します。
  * 値が小さいほどモデルの適合度が高く、モデル診断や比較に使用されます。
  * ポアソン分布のGLMでは、残差逸脱度が残差の自由度と近い値であれば、モデルは適切と考えられます。

## 有意性

モデルの有意性検定のためにF検定を行いました。帰無仮説は、「モデルの全ての係数が0である」、つまりモデルに使われた説明変数は目的変数である<%= target %>と関係がないということになります。P値の値が有意水準である<%= baseline_p_pct %>%より高ければ、選択された説明変数と<%= target %>の関係は統計的に有意とは言えません。逆に、P値が<%= baseline_p_pct %>%より低ければ、有意だと言えます。

{start_show_hide}
## モデルの指標の詳細
* P値
  * P値はモデルやパラメータの統計的有意性を示す確率値です。
  * 一般的に5%（0.05）未満であれば、統計的に有意であると判断されます。
  * 値は0から1の間で、P値が小さいほど統計的有意性が高いことを示します。

* 行数
  * 行数は分析に使用したデータの総数（サンプルサイズ）を示します。
  * サンプルサイズが大きいほど、統計的検定の検出力が高まり、結果の信頼性が向上します。
  * 説明変数にある数値型の列で欠損値が含まれている場合、その行が取り除かれて実行されます。

* 対数尤度
  * 対数尤度はデータがモデルにどれだけ適合しているかを数値化したものです。
  * 通常は負の値を取り、0に近いほどモデルの適合度が高いことを示します。
  * 主にAICやBICなどの情報量基準の計算に使用されます。

* AIC
  * AIC（赤池情報量基準）はモデルの複雑さと適合度のバランスを評価する指標です。
  * 値が小さいほど優れたモデルとされ、過学習を防ぎながら最適なモデルを選択するのに役立ちます。
  * 値は通常正ですが、対数尤度が大きい場合は負の値になることもあります。

* BIC
  * BIC（ベイズ情報量基準）はAICと同様にモデル選択のための指標ですが、サンプルサイズによる補正がより厳しくなっています。
  * AICよりも単純なモデルを選ぶ傾向があり、値が小さいほど良いモデルと判断されます。
  * 値は通常正ですが、対数尤度が大きい場合は負の値になることもあります。

* 残差逸脱度
  * 残差逸脱度は実測値とモデルによる予測値との差（残差）を測定する指標です。
  * 値が小さいほどモデルの適合度が高く、モデル診断や比較に使用されます。
  * 0以上の値を取り、完璧なモデルでは0になります。

* 残差の自由度
  * 残差の自由度は「データ量（行数） - モデルのパラメータ数」で計算されます。
  * 残差の評価や分散の推定に使用され、検定統計量の算出に必要です。

* Nullモデルの逸脱度
  * Nullモデルの逸脱度は、説明変数を含まない（切片のみの）モデルの逸脱度を示します。
  * モデルの逸脱度と比較することで、説明変数の追加によるモデル改善度を評価できます。
  * 値自体よりも、モデルの逸脱度との差が重要です。

* Nullモデルの自由度
  * Nullモデルの自由度はNull（切片のみの）モデルの自由度で、通常はデータ数-1です。
  * モデルの自由度と比較することで、説明変数の追加によって使用された自由度を確認できます。
  * モデル比較の際の参考値として使用されます。

* VIF（最大値）
  * VIF（分散拡大要因）は説明変数間の多重共線性の程度を示す指標です。
  * 一般的にVIFが10以上の変数は多重共線性の問題があると判断されます。
  * 値は1以上で、1に近いほど多重共線性が少ないことを示します。

{end_show_hide}

## 実測値と予測値の関係

<% if (!test_mode) { %>
予測した結果、元の実測値と予測値にはズレがありますが、それらの関係を散布図を使って可視化したのが以下のチャートです。それぞれの点はそれぞれの行を表しています。
<% } else { %>
予測した結果、元の実測値と予測値にはズレがありますが、それらの関係を散布図を使って可視化したのが以下のチャートです。それぞれの点はそれぞれの行を表しています。トレーニングデータは青色に、テストデータはオレンジ色として分けて可視化しています。
<% } %>

{start_lazy_show_hide}
### チャート
{{actual_predicted}}
{end_lazy_show_hide}

## 予測値と残差の関係

<% if (!test_mode) { %>
予測した結果、予測値と残差（元の実測値と予測値のズレ）の関係を散布図を使って可視化したのが以下のチャートです。それぞれの点はそれぞれの行を表しています。
<% } else { %>
予測した結果、予測値と残差（元の実測値と予測値のズレ）の関係を散布図を使って可視化したのが以下のチャートです。それぞれの点はそれぞれの行を表しています。トレーニングデータは青色に、テストデータはオレンジ色として分けて可視化しています。
<% } %>

{start_lazy_show_hide}
### チャート
{{predicted_residual}}
{end_lazy_show_hide}

<% if (!test_mode) { %>
## トレーニングデータに対する予測

トレーニングデータに対して、作成された予測モデルを使って予測した結果が以下の表となります。
<% } else { %>
## トレーニング・テストデータに対する予測

トレーニングデータとテストデータに対して、作成された予測モデルを使って予測した結果が以下の表となります。
<% } %>

{start_lazy_show_hide}
### 予測結果
{{data}}
{end_lazy_show_hide}

# 補足情報

## 次のステップ

* 変数選択の最適化：統計的に有意でない変数（P値が<%= baseline_p_pct %>%以上）を除外しモデルをシンプルにすることで、モデルの解釈がしやすくなり、過剰適合のリスクも減らすことができます。変数選択のガイドラインは[こちら](https://exploratory.io/note/exploratory/SWF4cTx8)のノートをご覧ください。
<% if (!repeat_by) { %>
* グループ別分析：グループごとに別々のモデルを作成することで、それぞれのグループ内での<%= target %>の決定要因をより詳細に分析できます。その場合は、「繰り返し」にグループとなる変数を選択し、実行し直すことができます。
<% } %>
* 外れ値の確認：予測精度に影響を与える可能性のある外れ値がないか確認し、必要に応じて対処することで、モデルの信頼性が向上する可能性があります。外れ値を除去する方法については、[こちら](https://exploratory.io/note/exploratory/Eep7kip3)のノートをご覧ください。
* 他の分布の検討：逆ガウス分布は非負の連続データで右に歪んだ分布のモデル化に適していますが、データの特性によっては他の分布（ガンマ分布など）も検討する価値があるかもしれません。
<% if (!test_mode) { %>
* モデルの評価：このモデルの予測性能をより厳密に評価するために、トレーニングデータとテストデータに分けて検証することができます。その場合は、[「設定」](//analytics/settings)より「検証」セクションの下の「テストモード」をTRUEに設定し、実行し直してください。
<% } %>
* 新しいデータに対する予測：作成したモデルを使って新しいデータに対して予測をしたいときには、予測をしたい対象のデータフレームに「モデルで予測（アナリティクス・ビュー）」のステップを追加します。詳細は、[こちらのノート](https://exploratory.io/note/exploratory/AAI3Mle3)をご参照ください。


`;

module.exports = template;
