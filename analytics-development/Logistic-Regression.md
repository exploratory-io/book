const template =
`

<% if (predictorColumns.length > 1) { %>
# 多重共線性

{{multicollinearity}}

<% if (has_perfect_collinearity) { %>
このモデルには<%= perfect_collinearity_variables %> によって完全な多重共線性（この説明変数が他の説明変数の値を足したり引いたり、何倍かして作られる数値で完全に表される状態）の問題が見られます。
この問題を解決するためには、説明変数の中から<%= perfect_collinearity_variables %>を除外し、再実行してください。
<% } else if (max_vif > 10) { %>

このモデルには多重共線性（複数の説明変数間に強い相関関係があること）の問題が見られます。VIFの値が10を超えている説明変数があると、個々の変数の効果を正確に評価することが難しくなります。
この問題を解決するためには、VIFの値が10を超えている説明変数の中から必要性が低いものを1つずつ除外し、再実行し、VIFの値が10を超える説明変数がなくなるまで繰り返してください。

<% } else { %>
このモデルには多重共線性（複数の説明変数間に強い相関関係があること）の問題は見られません。（VIFの値が10を超えている説明変数があると、個々の変数の効果を正確に評価することが難しくなります。）
<% } %>
<% } %>

# モデルの指標

<% if (!test_mode) { %>
モデルの予測精度や有意性に関する様々な指標を以下の表にまとめています。
<% } else { %>
モデルの予測精度や有意性に関する様々な指標を、以下の表にまとめています。現在テストモードであるため、予測精度に対してはトレーニングデータとテストデータ両方に対しての指標を表示しています。
<% } %>

{{summary}}

## 予測精度

### AUC

ロジカル型（TRUE/FALSE）を予測するモデルの予測精度の評価には一般的にAUCがよく使われます。値は0.5から1の間で、0.5はランダムな予測（コイン投げと同等）、1はTRUEとFALSEのデータを完全に分類できることを意味します。

<% if (auc > 0.9) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と非常に高く、このモデルは<%= target %>のTRUEとFALSEのデータを非常にうまく分類できることを示しています。
<% } else if (auc > 0.8) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と高く、このモデルは<%= target %>のTRUEとFALSEのデータをうまく分類できることを示しています。
<% } else if (auc > 0.6) { %>
AUCは<%= auc_pct %>% (<%= auc %>)と中程度で、このモデルは<%= target %>のTRUEとFALSEのデータをある程度うまく分類できることを示しています。
<% } else { %>
AUCは<%= auc_pct %>% (<%= auc %>)と低く、このモデルは<%= target %>のTRUEとFALSEをあまりうまく分類できないことを示しています。
<% } %>

### 正解率、F値

* 正解率、誤分類率、F1スコア、適合率、再現率はTRUE/FALSEの境界値の設定により影響されます。現在の境界値は<%= true_false_criteria %>に設定されていますが、これは[「設定」](//analytics/settings)より変更可能です。

## 有意性

<% if (p > baseline_p) { %>
モデルのP値は<%= p_pct %>% (<%= p %>)で、有意水準<%= baseline_p_pct %>% (<%= baseline_p %>) より高いため、選択された説明変数と<%= target %>の関係は統計的に有意とは言えません。
<% } else { %>
モデルのP値は<%= p_pct %>% (<%= p %>)で、有意水準<%= baseline_p_pct %>% (<%= baseline_p %>) より低いため、選択された説明変数と<%= target %>の関係は統計的に有意だと言えます。
<% } %>

{start_show_hide}
## モデルの指標の詳細
* AUC
  * AUC（Area Under the Curve）はROC曲線の下の面積で、モデルの予測精度を総合的に評価する指標です。
  * 値は0.5から1の間で、0.5はランダムな予測（コイン投げと同等）、1はTRUEとFALSEのデータを完全に分類できることを意味します。
  * 一般的に0.7以上で許容可能、0.8以上で良好、0.9以上で非常に優れた分類性能と解釈されます。

* F1スコア
  * F1スコアは適合率と再現率の調和平均で、両方のバランスを考慮したモデルの予測精度の指標です。
  * 値は0から1の間で、1に近いほど適当性と再現性のバランスが取れた優れたモデルであることを示します。
  * 元データのTRUEとFALSEの割合に大きな差がある場合に特に有用です。

* 正解率
  * 正解率（Accuracy）は全予測中の正しい予測の割合を示します。
  * 値は0から1の間で、1に近いほど多くの事例を正しく分類できることを意味します。
  * 元データのTRUEとFALSEの割合に大きな差がある場合、不均衡がある場合は誤解を招く可能性があります。

* 誤分類率
  * 誤分類率（Error Rate）は全予測中の誤った予測の割合で、1-正解率で計算されます。
  * 値は0から1の間で、0に近いほど誤分類が少ないことを意味します。
  * 正解率と同様に、元データのTRUEとFALSEの割合に大きな差がある場合は解釈に注意が必要です。

* 適合率 (Precision)
  * 適合率は「TRUEと予測したもののうち、実際にTRUEだった割合」を示します。
  * 値は0から1の間で、1に近いほど「TRUEと予測したものが実際にTRUEである精度」が高いことを意味します。
  * 偽陽性（実際はFALSEなのにTRUEと予測）を最小化したい場合に重視される指標です。

* 再現率 (Recall)
  * 再現率は「実際にTRUEであるもののうち、TRUEと正しく予測できた割合」を示します。
  * 値は0から1の間で、1に近いほど「実際のTRUEのケースを見逃さない能力」が高いことを意味します。
  * 偽陰性（実際はTRUEなのにFALSEと予測）を最小化したい場合に重視される指標です。

* P値
  * P値は観測されたデータが帰無仮説（説明変数と目的変数に関連がない）と同等かそれ以上に極端である確率を示します。
  * 一般的に5%（0.05）未満であれば、統計的に有意であると判断されます。
  * 値は0から1の間で、P値が小さいほど統計的有意性が高いことを示します。

* 行数 (TRUE)
  * 目的変数がTRUEのデータの行数を示します。
  * 極端にTRUEが少ない場合、モデルの学習や評価に偏りが生じる可能性があります。

* 行数 (FALSE)
  * 目的変数がFALSEのデータの行数を示します。
  * 極端にFALSEが少ない場合、モデルの学習や評価に偏りが生じる可能性があります。

* 行数
  * 行数は分析に使用したデータの総数（サンプルサイズ）です。
  * データ数が多いほど、モデルの信頼性が高まります。
  * 一般的に説明変数の数の10倍以上のサンプルサイズが推奨されます。

* 対数尤度
  * 対数尤度はモデルがデータにどれだけ適合しているかを数値化したものです。
  * 通常は負の値を取り、0に近いほどモデルの適合度が高いことを示します。
  * 単独では解釈が難しく、モデル比較のためのAICやBICの計算に使用されます。

* AIC
  * AIC（赤池情報量基準）はモデルの複雑さと適合度のバランスを評価する指標です。
  * 値が小さいほど優れたモデルとされ、過学習を防ぎながら最適なモデルを選択するのに役立ちます。
  * 同じデータセットで異なるモデルを比較する際に使用され、通常は正の値を取ります。

* BIC
  * BIC（ベイズ情報量基準）はAICと同様にモデル選択のための指標ですが、サンプルサイズによる補正がより厳しくなっています。
  * AICよりも単純なモデルを選ぶ傾向があり、値が小さいほど良いモデルと判断されます。
  * 大きなサンプルサイズでの分析や、真のモデルが比較的単純だと考えられる場合に有用です。

* 残差逸脱度
  * 残差逸脱度は実際の結果とモデルによる予測の差（残差）を測定する指標です。
  * 値が小さいほどモデルの適合度が高いことを示します。
  * 自由度と比較して大きな値の場合、モデルの適合が悪いことを示唆します。

* 残差の自由度
  * 残差の自由度は「データ数 - モデルのパラメータ数」で計算され、モデルの複雑さを考慮した残りの情報量を示します。
  * 常に正の整数値を取り、値が大きいほど推定の精度が高まります。
  * 残差逸脱度と合わせて、モデルの適合度を評価するのに使用されます。

* Nullモデルの逸脱度
  * Nullモデルの逸脱度は、説明変数を含まない（切片のみの）モデルの逸脱度を示します。
  * モデルの逸脱度と比較することで、説明変数の追加によるモデル改善度を評価できます。
  * 値自体よりも、モデルの逸脱度との差が重要です。

* Nullモデルの自由度
  * Nullモデルの自由度はNull（切片のみの）モデルの自由度で、通常はデータ数-1です。
  * モデルの自由度と比較することで、説明変数の追加によって使用された自由度を確認できます。
  * モデル比較の際の参考値として使用されます。

* VIF（最大値）
  * VIF（分散拡大要因）は説明変数間の多重共線性の程度を示す指標です。
  * 一般的にVIFが10以上の変数は多重共線性の問題があると判断されます。
  * 値は1以上で、1に近いほど多重共線性が少ないことを示します。

{end_show_hide}


# 変数間の関係

<% if (predictorColumns.length > 1) { %>
## 説明変数の重要度

<%= target %>を予測するためにどの説明変数が相対的により重要なのかを表したのが以下のチャートです。

{{variable_importance}}

<% } %>

## 説明変数の影響度

それぞれの説明変数の値が変わると、<%= target %>の値がどのように変わるかを表したのが以下のチャートです。

{{variable_effect}}

グレーの線は実測値とその95%信頼区間を、青い線（または点）は予測値を表します。
説明変数が数値型の場合は、他の変数が一定だった時に、X軸の値が1単位上がった時に予測値がどのように変化していくのかをラインチャートで可視化しています。説明変数が文字列型、ロジカル型の場合はその値での予測値を点として表現しています。

<% if (predictorColumns.length > 1) { %>

統計の予測モデルでは、他の変数が一定だとした時に、その説明変数単体の効果を予測しているため、実測値の平均値と予測値にずれが生じることがあります。もし実測値の平均値と予測値でずれが生じている場合は、その変数は他の変数の効果を内包していることを表します。

_説明変数は上記の「説明変数の重要度」にある重要度の高い順番で並んでいます。_
<% } %>

# 変数の係数（オッズ比）と有意性

変数ごとに係数（オッズ比）とその有意性を判断するためのP値、および信頼区間がリストされています。

{{coefficient_table}}

## オッズ比の解釈

それぞれの説明変数の値が1単位変わると<%= target %>のオッズ（TRUEになる可能性）が何倍上がる（または下がる）かを示します。

### オッズ比の解釈の例

<% variables.forEach(variable => { %>
<% if (variable.type == 'numeric') { %>
他の変数の値が一定の場合、<%= variable.variable %>が1単位上がると、<%= target %>のオッズ（TRUEの割合 / FALSEの割合）は約<%= variable.odds_ratio %>倍になります。
<% } else if (variable.type == 'logical') { %>
他の変数の値が一定の場合、<%= variable.variable %>がTRUEの場合、FALSEに比べ<%= target %>のオッズ（TRUEの割合 / FALSEの割合）は約<%= variable.odds_ratio %>倍になります。
<% } else { %>
他の変数の値が一定の場合、「<%= variable.variable %>」は、ベースレベルである「<%= variable.base_level %>」と比べて<%= target %>のオッズ（TRUEの割合 / FALSEの割合）が約<%= variable.odds_ratio %>倍になります。
<% } %>
<% }) %>

## P値を使った有意性の判断

有意水準が<%= baseline_p_pct %>% (<%= baseline_p %>)の元では、P値が<%= baseline_p_pct %>% (<%= baseline_p %>)よりも大きい説明変数は<%= target %>との関係が統計的に有意だとは言えません。逆に、P値が<%= baseline_p_pct %>% (<%= baseline_p %>)よりも小さい説明変数は<%= target %>との関係が統計的に有意だと言えます。

_現在の有意水準（P値）は<%= baseline_p_pct %>% (<%= baseline_p %>)に設定されていますが、これは[「設定」](//analytics/settings)より変更可能です。_


## オッズ比と信頼区間の可視化

それぞれの変数のオッズ比と有意性を可視化したのが以下のチャートです。

{{coefficient}}

* それぞれのエラーバーの真ん中の点はオッズ比の値、上下の線はその95%信頼区間を表しています。<%= target %>との関係が有意で、かつその関係が正の説明変数は青、関係が負の説明変数は赤となっています。グレーで表されている説明変数は<%= target %>との関係が有意とは言えません。
* オッズ比が1であるということは、説明変数の値が変化してもTRUEとFALSEのオッズ（TRUEの割合 / FALSEの割合）が変わらないため、<%= target %>との関係がないことを表します。
* オッズ比の95%信頼区間は、「真のオッズ比がこの範囲内にある可能性が高い（95%の信頼がある）」ということを意味します。そのため、信頼区間が1を含んでいる説明変数は、<%= target %>との関係が全くない可能性があるため、統計的に有意だと言えません。逆に、信頼区間が1を含んでいない説明変数は、<%= target %>との関係が全くない可能性はほぼないため、統計的に有意だと言えます。
* 有意性の判断はP値または信頼区間によって行うことができます。どちらで判断しても同じ結果となります。

_上記の信頼区間の説明は直感的な説明であって、正確には「同じ母集団から繰り返しサンプルを取り、毎回95％信頼区間を計算した場合、そのうちの95％の区間は真のオッズ比を含む」ということになります。_

### 注意点

* オッズ比は、確率の変化比ではなく、あくまでもオッズ（TRUEの割合 / FALSEの割合）の変化比です。
* オッズ比が1より大きい場合は<%= target %>がTRUEになる確率が高くなり、1より小さい場合は低くなります。
* これらのオッズ比の値は、あくまでもそれぞれの説明変数の値が1ポイント変わった場合の変化量であり、説明変数同士で単位が異なる場合にはそれらのオッズ比の値を使って<%= target %>との関係の強さを比べることはできません。説明変数間の関係の強さを比べたい場合は、上記の「説明変数の重要度」をご参照ください。


# 補足情報

<% if (!test_mode) { %>
## トレーニングデータに対する予測

トレーニングデータに対して、作成された予測モデルを使って予測した結果が以下の表となります。
<% } else { %>
## トレーニング・テストデータに対する予測

トレーニングデータとテストデータに対して、作成された予測モデルを使って予測した結果が以下の表となります。
<% } %>

{start_lazy_show_hide}
### 予測結果
{{data}}
{end_lazy_show_hide}

## 予測マトリックス（混同行列）

<% if (!test_mode) { %>
このモデルは<%= mode %>データのそれぞれの行に対してTRUEまたはFALSEと予測したわけですが、そのうちのどれだけが実測値においてTRUEまたはFALSEだったのかを対応表としてまとめたのが以下の表です。数値はそれぞれの組み合わせが全データに占める割合（％）です。

<% } else { %>
このモデルは<%= mode %>データのそれぞれの行に対してTRUEまたはFALSEと予測したわけですが、そのうちのどれだけが実測値においてTRUEまたはFALSEだったのかを対応表としてまとめたのが以下の表です。数値はそれぞれの組み合わせが全データに占める割合（％）です。現在テストモードであるため、トレーニングデータ、テストデータそれぞれに対する結果を表示しています。

<% } %>

{{confusion_matrix}}

## 予測確率の分布

このモデルは<%= mode %>データのそれぞれの行に対して<%= target %>の確率（0～1の間の値）を予測したわけですが、この確率の値の分布を実測値がTRUE（青）、FALSE（オレンジ）のグループに分けて可視化したのが以下のチャートです。

{{probability_distribution}}

<% if (test_mode) { %>
* 現在テストモードであるため、テストデータに対して予測した確率の分布となります。
<% } %>
* 実測値がTRUEのグループ（青線）は右側（1に近い確率）に、実測値がFALSEのグループ（オレンジ線）は左側（0に近い確率）に偏っているほど、モデルの予測精度が高いと言えます。
* 縦の点線は、TRUEとFALSEを分類するために現在設定されている確率の境界値を示しています。デフォルトは50％（0.5）ですが、[「設定」](//analytics/settings)より変更可能です。
* この分布からモデルの分類性能や、最適なTRUE/FALSEの境界値の調整を視覚的に確認できます。


## ROC曲線

<% if (!test_mode) { %>
モデルの分類性能を様々なTRUE/FALSEの境界値で評価するROC曲線が以下のチャートです。Y軸は真陽性率（感度）、X軸は偽陽性率（1-特異度）を表しています。青い線は今回のモデルのROC曲線で、対角線の灰色の点線はランダムな予測（AUC: 0.5）を意味します。ROC曲線は左上に膨らむほど予測精度が高く、対角線に近いほど予測精度が低いことを示します。
<% } else { %>
モデルの分類性能を様々なTRUE/FALSEの境界値で評価するROC曲線が以下のチャートです。Y軸は真陽性率（感度）、X軸は偽陽性率（1-特異度）を表しています。青い線は今回のモデルのテストデータに対するROC曲線、オレンジの線はトレーニングデータに対するROC曲線です。対角線の灰色の点線はランダムな予測（AUC: 0.5）を意味します。ROC曲線は左上に膨らむほど予測精度が高く、対角線に近いほど予測精度が低いことを示します。
<% } %>

{{roc_curve}}

## 次のステップ

* 変数選択の最適化：統計的に有意でない変数（P値が<%= 100 * baseline_p %>%以上）を除外しモデルをシンプルにすることで、モデルの解釈がしやすくなり、過剰適合のリスクも減らすことができます。
* グループ別分析：グループごとに別々のモデルを作成することで、それぞれのグループ内での<%= target %>の決定要因をより詳細に理解できるかもしれません。その場合は、「繰り返し」にグループとなる変数を選択し、実行し直すことができます。
* 非線形関係の検討：<%= target %>と非線形の関係を持つ説明変数はデータを加工することで、より正確にモデル化することができます。
* 外れ値の確認：予測精度に影響を与える可能性のある外れ値がないか確認し、必要に応じて対処することで、モデルの信頼性が向上する可能性があります。
<% if (!test_mode) { %>
* モデルの評価：このモデルの予測性能をより厳密に評価するために、トレーニングデータとテストデータに分けて検証することができます。その場合は、[「設定」](//analytics/settings)より「検証」セクションの下の「テストモード」をTRUEに設定し、実行し直してください。
<% } %>

`;

module.exports = template;
