# LightGBMの紹介

LightGBMは複数のモデルに学習させ、それぞれの予測結果を一つの予測にまとめるアンサンブル学習の代表的なアルゴリズムの一つです。[XGBoost](https://ja.exploratory.io/note/exploratory/XGBoost-Gbn5oUn5)と同じ勾配ブースティングのファミリーに属しており、決定木を一つずつ順に作っていき、前の決定木の予測で間違ったデータに重みをかけて、次の決定木ではその間違いをカバーするように学習を進めていくアルゴリズムです。

LightGBMはMicrosoftが開発したフレームワークで、XGBoostに対していくつかの独自技術を導入することで、より高速でメモリ効率の良い学習を実現しています。主な違いとして、XGBoostがデフォルトでは木の各レベルを均等に分割していく「Level-wise」という成長戦略を取るのに対し、LightGBMは損失関数の低減に最も寄与する葉を優先的に分割する「Leaf-wise」という成長戦略を取ります。これにより、同じ葉の数でもXGBoostのLevel-wiseより低い損失を達成できます。

また、LightGBMには勾配の大きさに基づいてサンプリングを行うGOSS（Gradient-based One-Side Sampling）や、排他的な特徴量を束ねるEFB（Exclusive Feature Bundling）、連続値をビンに離散化して分割点を探索するヒストグラムベースアルゴリズムといった技術が搭載されており、大規模データでも高速に学習できることからKaggleなどのデータ分析コンペティションでも広く利用されています。

なお、LightGBMもXGBoostと同じく、複数の決定木を並列に作成し、その多数決（分類の場合）や平均（回帰の場合）で予測する[ランダムフォレスト](https://ja.exploratory.io/note/exploratory/Vfg2fEA8)とは異なり、決定木を順に作成していくブースティング型のアルゴリズムです。

# 必要なデータの形式

LightGBMを実行する際には、1行が1観測対象となっているデータを使う必要があります。目的変数には数値型、ロジカル型のどちらも扱うことができます。予測変数におけるデータタイプには特に縛りはありません。しかし、予測変数同士の相関が強い場合は影響度を取り合ってしまい、変数重要度の順番が低く見積もられることがあります。

![](libs/exploratory/images/p1.png)

# サンプルデータ

今回はサンプルデータとして、従業員データを使用していきます。このデータは1行が1従業員のデータで、列には年齢や給料、職種など従業員の属性を表す列があります。

![](libs/exploratory/images/p2.png)

サンプルデータをインポートするには、プロジェクトのデータフレーム一覧画面の「+」ボタンからデータのインポートを開始し、「サンプルデータ」タブから従業員データを選択してください。

![](libs/exploratory/images/p3.png)

# LightGBMを実行する

今回は、従業員の「給料」を予測するLightGBMのモデルを作成します。

![](libs/exploratory/images/p4.png)

アナリティクスビューを開き、タイプに「LightGBM」を選択します。

![](libs/exploratory/images/p5.png)

目的変数に「給料」を選択します。

![](libs/exploratory/images/p6.png)

予測変数の列をクリックして、給料を予測する上で使用する列を選択します。列の選択画面では、個別に列を選ぶことも、列の範囲を指定してまとめて選ぶこともできます。

![](libs/exploratory/images/p7.png)

予測変数を設定したら、「実行」ボタンをクリックします。

![](libs/exploratory/images/p8.png)

# 結果の解釈

## 変数重要度

変数重要度タブでは、どの変数が目的変数とより相関が強いのか、予測する時により重要なのかを調べることができます。

![](libs/exploratory/images/p9.png)

棒グラフが長い変数ほど、給料を予測する上で重要であることを意味します。今回の例では、職位（Job Level）が給料を予測する上で圧倒的に重要であることがわかります。

![](libs/exploratory/images/p10.png)

次に重要な変数として、職種（Job Role）や勤続年数（Total Working Years）が続いています。これは、職位が高いほど給料が高い傾向があり、また特定の職種や長い勤続年数も給料に影響を与えていることを示しています。

![](libs/exploratory/images/p11.png)

変数重要度の棒グラフにマウスをホバーすると、各変数の重要度の具体的な値を確認できます。

![](libs/exploratory/images/p12.png)

## 予測

予測タブでは、それぞれの変数の値が変わると、目的変数の値はどのように変わるのかがわかります。これはPartial Dependence Plot（PDP）と呼ばれる手法で可視化されています。

![](libs/exploratory/images/p13.png)

グレーの線は実測値を、青い線は予測値（モデルが推定した値）を示しています。例えば、職位（Job Level）ごとの給料の変化を見ると、職位が上がるにつれて給料が大きく上昇する傾向が確認できます。

![](libs/exploratory/images/p14.png)

予測変数を切り替えることで、各変数と給料の関係を確認できます。

![](libs/exploratory/images/p15.png)

勤続年数（Total Working Years）の場合は、年数が増えるにつれて給料が緩やかに上昇していく傾向が見て取れます。

![](libs/exploratory/images/p16.png)

カテゴリカル変数（文字列型の変数）の場合は、カテゴリーごとの予測値が表示されます。

![](libs/exploratory/images/p17.png)

## 学習

学習タブでは、学習回数（作成された決定木の数）によって、予測精度がどれだけ向上したかが確認できます。

![](libs/exploratory/images/p18.png)

デフォルトの学習回数は10回になっていますが、プロパティから変更いただけます。また、それ以外にもEarly Stoppingの学習回数（学習した結果、予測精度が向上しない時に打ち切る回数）や、学習の際に使用する指標も変更できます。

![](libs/exploratory/images/p19.png)

## サマリ

サマリタブでは、この予測モデルの評価を確認できます。

![](libs/exploratory/images/p20.png)

R2乗はデータの平均からのばらつきをモデルが説明できている割合の指標で、0から1の間の値を取ります。1に近ければ近いほど、モデルがデータのばらつきをよく説明できていることを示します。例えばR2乗が0.95であれば、データのばらつきの95%をこのモデルで説明できていることになります。RMSEはモデルの予測誤差の大きさを示す指標です。

![](libs/exploratory/images/p21.png)

## データ

データタブでは、モデルに使用したデータと予測値をテーブル形式で確認できます。目的変数である給料と、このモデルで算出された予測値（Predicted Value）を並べて確認することで、モデルの予測がどの程度正確かを個別のデータレベルで把握できます。

![](libs/exploratory/images/p22.png)

# まとめ

LightGBMはMicrosoftが開発した勾配ブースティングフレームワークで、XGBoostと同様に複数の決定木を順に作成して予測精度を高めていくアルゴリズムです。Exploratoryのアナリティクスビューでは、タイプに「LightGBM」を選択し、目的変数と予測変数を指定して実行するだけで、変数重要度や予測、学習の過程、サマリなどの結果をすぐに確認することができます。

LightGBMはLeaf-wise成長戦略やGOSS、EFBといった独自技術により、XGBoostと比較してより高速な学習とメモリ効率の良さを実現しています。特に大規模なデータを扱う場合にその違いが顕著になるため、データの規模や分析の目的に応じてXGBoostと使い分けることで、より効率的にデータ分析を進めることができます。

## 参考資料

* [XGBoostの紹介](https://ja.exploratory.io/note/exploratory/XGBoost-Gbn5oUn5)
* [決定木の紹介](https://ja.exploratory.io/note/exploratory/GEQ0ssi1)
* [ランダムフォレストの使い方](https://ja.exploratory.io/note/exploratory/Vfg2fEA8)
* [アナリティクスの文法を使った予測モデルの解釈](https://ja.exploratory.io/note/exploratory/sRh1hDn7)
* [機械学習モデルを使った予測と検証](https://ja.exploratory.io/note/exploratory/fnN6YHq8)
* [なぜ表形式データの場合、ツリー系モデルが深層学習モデルに勝るのか](https://ja.exploratory.io/note/kanaugust/XGBoost-knM4aqw2IL)

# LightGBMに関するよくある質問

### Q: 予測タブで表示されている実測値はどのように求められているのですか？

予測タブの実測値はそれぞれの予測変数のデータタイプによって表示が異なります。数値型の予測変数の場合は、X軸に予測変数の値、Y軸に目的変数の実測値をプロットした散布図のような表示になります。カテゴリカル変数の場合は、カテゴリーごとの目的変数の分布が表示されます。

![](libs/exploratory/images/p23.png)

### Q: 予測タブで表示されている予測値はどのように求められているのですか？

予測値はPartial Dependence Plot（PDP）と呼ばれる手法で算出されています。PDPは、注目している変数以外の変数の影響を平均化することで、注目している変数の値を変化させた時に予測結果がどのように変わるかを可視化したチャートです。例えば、職位と給料の関係を調べたい場合、職位以外の変数（年齢、職種、勤続年数など）は全データの平均的な値として固定し、職位だけを変化させた時の予測値の平均を計算します。これにより、職位が給料に与える「純粋な影響」を確認できます。

![](libs/exploratory/images/p24.png)

### Q: カテゴリーを予測したモデルを使って新しいデータに対して予測をした際に、予測ラベルに欠損値が出てしまう

この問題が発生する主な原因は2つあります。1つ目は、モデル作成時の学習データに存在しなかったカテゴリー値が新しいデータに含まれている場合です。モデルは学習時に見たことのないカテゴリー値に対して予測を行うことができません。この場合は、新データの当該カテゴリー値を学習データに存在する値に変換するか、モデルを学習データに新しいカテゴリー値を含めた状態で再作成する必要があります。2つ目は、新しいデータの予測変数に欠損値が含まれている場合です。予測に使用する列に欠損値がある場合は、事前に欠損値を補完するか、欠損値のある行を除外してから予測を実行してください。

![](libs/exploratory/images/p25.png)
